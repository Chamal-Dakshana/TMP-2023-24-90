import os
import zipfile
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3, ResNet50, VGG16, MobileNetV2, DenseNet121
from tensorflow.keras.layers import Input, Lambda, GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, accuracy_score
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

unzip_destination = '/content/drive/MyDrive/Colab Notebooks/data'

# Define paths to training and testing data
train_path = os.path.join(unzip_destination, 'train')
test_path = os.path.join(unzip_destination, 'test')

# Image preprocessing and augmentation for training
train_datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)

# Image preprocessing for testing (no augmentation, just rescaling)
test_datagen = ImageDataGenerator()

# Define CNN architectures and their respective target sizes
cnn_architectures = {
    'InceptionV3': {'model': InceptionV3, 'size': 299},
    'ResNet50': {'model': ResNet50, 'size': 224},
    'VGG16': {'model': VGG16, 'size': 224},
    'MobileNetV2': {'model': MobileNetV2, 'size': 224},
    'DenseNet121': {'model': DenseNet121, 'size': 224}
}

# Table to store results
results_table = pd.DataFrame(columns=['Model', 'Accuracy', 'Loss'])

for name, info in cnn_architectures.items():
    print(f"Training and evaluating {name}")
    target_size = (info['size'], info['size'])

    # Load images from directories and apply transformations
    train_generator = train_datagen.flow_from_directory(
        train_path,
        target_size=target_size,
        batch_size=32,
        class_mode='categorical',
        color_mode='grayscale'
    )

    test_generator = test_datagen.flow_from_directory(
        test_path,
        target_size=target_size,
        batch_size=32,
        class_mode='categorical',
        color_mode='grayscale'
    )

    # Create a custom input layer that takes grayscale images and replicates them across three channels
    input_tensor = Input(shape=(info['size'], info['size'], 1))
    x = Lambda(lambda x: tf.tile(x, multiples=[1, 1, 1, 3]))(input_tensor)

    # Load the pre-trained model
    base_model = info['model'](weights='imagenet', include_top=False, input_tensor=x)

    # Set the layers of the base model to not be trainable
    for layer in base_model.layers:
        layer.trainable = False

    # Add custom layers on top
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dropout(0.5)(x)  # Dropout layer to prevent overfitting
    predictions = Dense(3, activation='softmax')(x)  # 3 classes: benign, malignant, normal

    # This is the model we will train
    model = Model(inputs=input_tensor, outputs=predictions)

    # Compile the model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    history = model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // train_generator.batch_size,
        epochs=50,  # Set a high number, monitor performance and adjust as needed
        validation_data=test_generator,
        validation_steps=test_generator.samples // test_generator.batch_size
    )

    # Save the model
    model_filename = f'thyroid_cancer_detector_{name}.h5'
    model.save(model_filename)
    print(f"Model saved as {model_filename}")

    # Evaluate the model
    eval_result = model.evaluate(test_generator)
    print(f'{name} - Test Loss: {eval_result[0]} - Test Accuracy: {eval_result[1]}')

    # Store results in the table
    results_table = results_table.append({'Model': name, 'Accuracy': eval_result[1], 'Loss': eval_result[0]}, ignore_index=True)

    # Plot training and validation accuracy per epoch
    plt.figure(figsize=(10, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{name} Training and Validation Accuracy')
    plt.legend()

    # Plot training and validation loss per epoch
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'{name} Training and Validation Loss')
    plt.legend()
    plt.show()

# Display the results table
print(results_table)

# Plot the results table for accuracy
results_table.set_index('Model', inplace=True)
results_table['Accuracy'].plot(kind='bar')
plt.title('Model Comparison - Accuracy')
plt.ylabel('Accuracy')
plt.show()

# Plot the results table for loss
results_table['Loss'].plot(kind='bar')
plt.title('Model Comparison - Loss')
plt.ylabel('Loss')
plt.show()

# After the model evaluation
test_generator.reset()  # Reset the generator to avoid shuffling issues
predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Confusion Matrix
conf_matrix = confusion_matrix(true_classes, predicted_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Classification Report
cls_report = classification_report(true_classes, predicted_classes, target_names=class_labels)
print(cls_report)

# Feature Maps Visualization
# Choose a layer to visualize (e.g., the first convolutional layer)
layer_name = 'conv2d'  # Replace with your layer's name
intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)

# Choose an image to visualize
img_to_visualize = test_generator.next()[0][0]  # Get an image from the test generator
img_to_visualize = np.expand_dims(img_to_visualize, axis=0)  # Expand dims to fit model input

# Get feature maps
feature_maps = intermediate_layer_model.predict(img_to_visualize)

# Plot the feature maps
number_of_feature_maps = feature_maps.shape[-1]
fig, axes = plt.subplots(1, number_of_feature_maps, figsize=(20, 3))
for i in range(number_of_feature_maps):
    ax = axes[i]
    ax.imshow(feature_maps[0, :, :, i], cmap='viridis')
    ax.axis('off')
plt.suptitle(f'Feature Maps of Layer {layer_name}')
plt.show()
